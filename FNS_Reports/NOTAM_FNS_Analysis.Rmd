---
title: 'NOTAM Frequency Analysis - 2020'
output:
  html_document:
    fig_caption: true
    df_print: paged
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: yes
      smooth_scroll: yes
---

<!-- Add the following line manually to the rendered HTML document so that IE does not block the javascript elements: -->
<!-- saved from url=(0014)about:internet --> 

Goals: 

- Produce visuals of NOTAM frequencies by date, with data downloaded from FNS Reports site
- Filter out NOTAMS within 10 minutes of the same ID
- Frequency distributions of counts of NOTAMs by date
- Prepare data for staffing models by service area 


```{r setup, echo = F, message=F}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

source('Utility/get_packages.R')

library(tidyverse)
library(plotly)    # for interactive plots
library(kableExtra)# for better tables

# Working directory: This sets the path to my H: drive if being run from my computer, otherwise put in your own path
workingdir <- file.path(getwd(), 'Data/NOTAMS')

# knitr::opts_knit$set(root.dir = workingdir)

```

```{r compile}
# Loop over reports and compile

if(!file.exists('FNS_NOTAMS.RData')){

  files_to_read = dir(workingdir)
  
  compiled = vector()
  
  for(f in files_to_read){
    fx <- read.csv(file.path(workingdir, f))
    compiled = rbind(compiled, fx)
    cat('. ')
  }
  
  # format date-time
  compiled <- compiled %>%
    mutate(Start.Date.UTC = strptime(Start.Date.UTC, format = '%m/%d/%Y %H%M', tz = 'UTC'),
           End.Date.UTC = strptime(End.Date.UTC, format = '%m/%d/%Y %H%M', tz = 'UTC'),
           Action.Date = strptime(Action.Date, format = '%m/%d/%Y %H%M', tz = 'UTC'),
           Cancellation.Date = strptime(Cancellation.Date, format = '%m/%d/%Y %H%M', tz = 'UTC'))
  
  # Order by Reference.ID and omit any duplicates with Action.Date within 10 minutes
  d <- compiled[order(compiled$Reference.ID, compiled$Action.Date),]
  
  counts_1 = c(nrow(d), length(unique(d$Reference.ID))) 
  
  d <- d %>%
    filter(action != 'Initiated') %>%
    filter(action != 'Submitted for review')
  
  counts_2 = c(nrow(d), length(unique(d$Reference.ID))) 
  
  dt <- d %>%
    group_by(Reference.ID) %>%
    mutate(action_time_diff = as.numeric(Action.Date-lag(Action.Date), units = 'mins')) %>%
    ungroup() %>%
    filter(action_time_diff >= 10 | is.na(action_time_diff))
  
  View(dt %>% select(Reference.ID, Action.Date, action_time_diff))
  
  counts_3 = c(nrow(dt), length(unique(dt$Reference.ID))) 

  # kable(table(dt$action), format = 'simple') 
  
  
} else {
  load('FNS_NOTAMS.RData')
}

# Omit 'Initiated' and 'Submitted for review' first, then do the 10 min grouping 
# Count total NOTAMS rows at each step
# Count total NOTAMS and total rows at each FPA
# Count total NOTAMS and total rows at each Service Area

# kable(rbind(counts_1, counts_2, counts_3), format = 'simple') 

```

The original data set contains `r format(nrow(d), big.mark = ',')` NOTAMS, from `r min(d$Action.Date)` to `r max(d$Action.Date)` with `r format(length(unique(d$Reference.ID)), big.mark = ',')` unique NOTAM Reference IDs.

After removing NOTAMS within 10 minutes of each other (for the same Reference ID), the remaining full set of NOTAMS is `r format(nrow(dt), big.mark = ',')` total observations from `r format(length(unique(dt$Reference.ID)), big.mark = ',')` unique NOTAM Reference IDs.

```{r format}

# Season: First define months from date time, then manually code months into seasons with a series of if/else statements nested together.

if(!file.exists('FNS_NOTAMS.RData')){
  df <- dt %>% 
    mutate(dow = format(Action.Date, '%A')) %>%
    mutate(date = as.Date(Action.Date)) %>%
    mutate(year = format(Action.Date, '%Y')) %>%
    mutate(quarter = as.factor(quarters(Action.Date)),
           month   = format(Action.Date, '%m'),
           season  = as.factor(ifelse(month == '12' | month == '01' | month == '02', 'Winter',
                                      ifelse(month == '03' | month == '04' | month == '05', 'Spring',
                                             ifelse(month == '06' | month == '07' | month == '08', 'Summer',
                                                    ifelse(month == '09' | month == '10' | month == '11', 'Fall', NA)))))) %>% 
      group_by(FPA, date, year, month, season) %>% 
    summarize(count = n())
  
  write.csv(df, file = 'FNS_NOTAM_count_by_day.csv', row.names=F)
  
  
  save(list = c('d', 'dt', 'df'), file = 'FNS_NOTAMS.RData')
}
```

## Summarize counts

Counts of NOTAMs by FPA (total rows and unique NOTAMs)

```{r summary1}

fpa_count <- dt %>%
  group_by(FPA) %>%
  summarize(`Total rows` = n(),
            `Unique NOTAMs` = length(unique(Reference.ID)))


kable(fpa_count, format = 'simple')

```

Same, but now grouped into regions

```{r summary2}
fpa_groups <- readxl::read_xlsx(file.path(getwd(), 'Data', 'FPA_Regions.xlsx'))

dt_Region = left_join(dt, fpa_groups, by = 'FPA') 

fpa_count <- dt_Region %>%
  group_by(Region) %>%
  summarize(`Total rows` = n(),
            `Unique NOTAMs` = length(unique(Reference.ID)))

kable(fpa_count, format = 'simple')

```

## Plotting


### Count of NOTAMs by date

```{r dateplot2, warning=FALSE}

g1.1 <- ggplot(df, aes(x = date, y = count)) +
  geom_point(alpha = 0.1) +          
  geom_smooth(span = 0.1) +                                         # Add a spline through these
  theme_bw() + 
  scale_color_discrete(name = "Day of Week") +                        
  ylab("NOTAM counts") + xlab('Date') +
  ggtitle("Count of NOTAMs by date over the study period ")    

ggsave(plot = g1.1, filename = "NOTAM_Freq_timeline_we.jpg", width = 6, height = 5) 

# ggplotly(g1.1)

```

### 2. Histograms by season

This figure shows the distribution of the count of NOTAMs by date. Each bar represents a range of NOTAM counts, and the height of bar indicates number of days with that many NOTAMs. The vertical colored lines indicate the mean count of NOTAMs for that season. 

```{r hists}

# Make data frame of mean values
df_mc <- df %>%
  group_by(season) %>%
  summarize(mean_count = mean(count))

g2 <- ggplot(df, aes(count)) +
  geom_histogram(color = "grey20",                                   # Create histograms
                 fill = "#0088BB",
                 bins = 50) +
  geom_vline(aes(xintercept = mean_count), data = df_mc) +
  facet_wrap(~season) +                                              # Make this a multi-panel figure by season
  scale_fill_discrete(name = "Day of Week") +                        # Set the name for the legend
  guides(color = FALSE) +                                            # Suppress legend for vertical lines
  theme_bw() +
  ylab("Count of days") + xlab("Count of NOTAMs") +
  ggtitle("Histograms of NOTAM counts by day")

# Add annotations for each vertical line
df_mc <- df_mc %>%
  mutate(y = 30,
         x = mean_count)

g3 = g2 + geom_text(data = df_mc, 
               mapping = aes(x = x, y = y, 
                             label = round(mean_count, 0)),
               size = 3,
               hjust = 1); g3

ggsave(plot = g3, filename = "NOTAM_Freq_histograms.jpg", width = 6, height = 5)            

```



```{r hists_FPA}

pdf('FPA_NOTAM_hists.pdf', width = 8, height = 8)

for(x in unique(d$FPA)){
  
  df_x = df %>% filter(FPA == x)
  
  # Make data frame of mean values
  df_mc <- df_x %>%
    group_by(season) %>%
    summarize(mean_count = mean(count))
  
  g2 <- ggplot(df_x, aes(count)) +
    geom_histogram(color = "grey20",                                   # Create histograms
                   fill = "#DD00BB",
                   bins = 50) +
    geom_vline(aes(xintercept = mean_count), data = df_mc) +
    facet_wrap(~season) +                                              # Make this a multi-panel figure by season
    scale_fill_discrete(name = "Day of Week") +                        # Set the name for the legend
    guides(color = FALSE) +                                            # Suppress legend for vertical lines
    theme_bw() +
    ylab("Count of days") + xlab("Count of NOTAMs") +
    ggtitle(paste0(x, ": Histograms of NOTAM counts by day"))
  
  # Add annotations for each vertical line
  df_mc <- df_mc %>%
    mutate(y = 30,
           x = mean_count)
  
  g3 = g2 + geom_text(data = df_mc, 
                 mapping = aes(x = x, y = y, 
                               label = round(mean_count, 0)),
                 size = 3,
                 hjust = 1)
  
  print(g3)

}

dev.off()

```


```{r hists_FPA_grouped}

# Group by W, C, E
fpa_groups <- readxl::read_xlsx(file.path(getwd(), 'Data', 'FPA_Regions.xlsx'))

df_Region = left_join(df, fpa_groups, by = 'FPA') %>%
  group_by(Region, date, year, month, season) %>%
  summarize(count = sum(count))

evaluated_regions = c()

pdf('FPA_Grouped_NOTAM_hists.pdf', width = 8, height = 8)

for(x in unique(df_Region$Region)[c(3,1,2)]){ # rearranging so Western is first
  evaluated_regions <- append(evaluated_regions, x)
  region_title_text = paste(evaluated_regions, collapse = " + ")
  
  df_x = df_Region %>% filter(Region %in% evaluated_regions)
  df_x = df_x %>% group_by(date, year, month, season) %>%
    summarize(count = sum(count))
  
  # Make data frame of mean values
  df_mc <- df_x %>%
    group_by(season) %>%
    summarize(mean_count = mean(count))
  
  g2 <- ggplot(df_x, aes(count)) +
    geom_histogram(color = "grey20",                                   # Create histograms
                   fill = "#CCAA00",
                   bins = 50) +
    geom_vline(aes(xintercept = mean_count), data = df_mc) +
    facet_wrap(~season) +                                              # Make this a multi-panel figure by season
    scale_fill_discrete(name = "Day of Week") +                        # Set the name for the legend
    guides(color = FALSE) +                                            # Suppress legend for vertical lines
    theme_bw() +
    ylab("Count of days") + xlab("Count of NOTAMs") +
    ggtitle(paste0(region_title_text, " Service Area: Histograms of NOTAM counts by day"))
  
  # Add annotations for each vertical line
  df_mc <- df_mc %>%
    mutate(y = 30,
           x = mean_count)
  
  g3 = g2 + geom_text(data = df_mc, 
                 mapping = aes(x = x, y = y, 
                               label = round(mean_count, 0)),
                 size = 3,
                 hjust = 1)
  
  print(g3)

}

dev.off()

```

# Staffing model analysis prep

Prepares data for staffing model work.

```{r busy_period_param}
# begin: busy period search parameters ----

#decide how much of the available data will be used for model building (versus model testing)
# min_hours_on_call_worker <- 4L
ignore_overlapping_busy_periods = TRUE
busy_periods_calendar_day_flag = TRUE
block_size_hours <- 24L #expecting integer 0-24

stopifnot(block_size_hours>=0L & block_size_hours<=24L & typeof(block_size_hours) == "integer")

earliest_datetime <- min(d$Action.Date)
print(earliest_datetime)

latest_datetime <- max(d$Action.Date)
print(latest_datetime)

earliest_complete_day <- as.Date(earliest_datetime)

latest_complete_day <- as.Date(latest_datetime)

if(block_size_hours == 24){ #leaving out the partial days 
  earliest_datetime <- earliest_complete_day
  latest_datetime <- latest_complete_day
}
print(earliest_datetime)
print(latest_datetime)

study_start <- earliest_datetime

study_length_whole_days <- as.integer(1 + difftime(latest_datetime, study_start, units = "days"))
  
share_of_study_for_model_building <- 1

model_build_days <- as.integer(study_length_whole_days * share_of_study_for_model_building)

model_build_hours <- model_build_days*24
offset <- 0 # e.g., 0 for model build, 60*60*model_build_hours for model test

top_block_list_size <- model_build_hours # 25L
```

```{r create_hr_blocks}
# Create hour blocks from data frame dt, counting number of NOTAMS in each hour across the study period, by Service Area
# Join fpa groups to dt to add the service area Region. Then make it smaller by only selecting the columns we need

dt <- dt %>%
  left_join(fpa_groups, by = 'FPA') %>%
  select(FPA, Region, action, Action.Date)

# Make hour blocks to group by
dt <- dt %>%
  mutate(yr_hour = as.POSIXct(format(Action.Date, '%Y-%m-%d %H'), format = '%Y-%m-%d %H', origin = "1970-01-01", tz = "UTC"))


dt_hr <- dt %>%
  group_by(Region, yr_hour) %>%
  summarize(hourly_count = n()) %>%
  mutate(hourly_count_rank = rank(1/hourly_count))
  
```

```{r staffing_prep}

orig_dt_hr <- dt_hr %>%
  mutate(date = as.Date(yr_hour), 
         dow = format(yr_hour, '%A'),
         hour = format(yr_hour, '%H'),
         month   = format(yr_hour, '%m'),
         season  = as.factor(ifelse(month == '12' | month == '01' | month == '02', 'Winter',
                                    ifelse(month == '03' | month == '04' | month == '05', 'Spring',
                                           ifelse(month == '06' | month == '07' | month == '08', 'Summer',
                                                  ifelse(month == '09' | month == '10' | month == '11', 'Fall', NA))))),
         peak2 = ifelse(hour >= 13 & hour <= 21, 'peak', 'off-peak'),
         peak3 = ifelse(hour >= 13 & hour <= 21, 'peak',
                        ifelse(hour >= 5 & hour <= 10, 'valley', 'off-peak'))
  ) 

```

```{r saveoutput}
# Save output to working directory ----

save(list = c('dt', 
              'df',
              'fpa_groups',
              'orig_dt_hr'),
     file = 'FNS_NOTAM_Freq_w_busy_days.RData')

```
