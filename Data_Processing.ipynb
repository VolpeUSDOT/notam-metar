{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTAM + METAR Data Processing\n",
    "\n",
    "Goals:\n",
    "- Summarize available NOTAM data from prepared notam_extract file. \n",
    "- Select example set of facilities (airports) and obtain METARs for the corresponding facilities and date ranges. \n",
    "    + Obtain METARs by accessing API\n",
    "    + Focus on ceiling and runway visual range. Will require some regular expression processing to extract cloud ceiling altitutde. Take the minimum value of each at each facility and time point. \n",
    "- Integrate the two. Will require decisions on temporal resolution.\n",
    "- Prepare data for visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from os import path\n",
    "\n",
    "import seaborn as sns\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read NOTAM extract. Obtain data file from shared Box.com site and place in ~/Documents/Notam_local\n",
    "data_dir = r'~\\Documents\\Notam_Local' \n",
    "\n",
    "notam = pd.read_excel(path.join(data_dir, 'notam_extract.xlsx'), sheet_name = \"data\", header = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>notam_location</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KSZY</td>\n",
       "      <td>2019-04-02 01:44:00.0</td>\n",
       "      <td>2019-04-17 00:44:00.0</td>\n",
       "      <td>OBST</td>\n",
       "      <td>OBST TOWER LGT (ASR 1269190) 352126.80N0882231...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KCXW</td>\n",
       "      <td>2019-04-02 01:46:00.0</td>\n",
       "      <td>2019-04-17 00:46:00.0</td>\n",
       "      <td>OBST</td>\n",
       "      <td>OBST TOWER LGT (ASR 1212822) 345040.40N0923322...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KUOS</td>\n",
       "      <td>2019-04-02 01:49:00.0</td>\n",
       "      <td>2019-04-17 00:49:00.0</td>\n",
       "      <td>OBST</td>\n",
       "      <td>OBST TOWER LGT (ASR 1052889) 351222.50N0854828...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M95</td>\n",
       "      <td>2019-04-02 01:50:00.0</td>\n",
       "      <td>2019-04-17 00:50:00.0</td>\n",
       "      <td>OBST</td>\n",
       "      <td>OBST TOWER LGT (ASR 1248915) 334516.20N0875825...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2A8</td>\n",
       "      <td>2019-04-02 01:54:00.0</td>\n",
       "      <td>2019-04-17 00:54:00.0</td>\n",
       "      <td>OBST</td>\n",
       "      <td>OBST TOWER LGT (ASR 1280021) 340633.40N0870610...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  notam_location             start_time               end_time keyword  \\\n",
       "0           KSZY  2019-04-02 01:44:00.0  2019-04-17 00:44:00.0    OBST   \n",
       "1           KCXW  2019-04-02 01:46:00.0  2019-04-17 00:46:00.0    OBST   \n",
       "2           KUOS  2019-04-02 01:49:00.0  2019-04-17 00:49:00.0    OBST   \n",
       "3            M95  2019-04-02 01:50:00.0  2019-04-17 00:50:00.0    OBST   \n",
       "4            2A8  2019-04-02 01:54:00.0  2019-04-17 00:54:00.0    OBST   \n",
       "\n",
       "                                                text  \n",
       "0  OBST TOWER LGT (ASR 1269190) 352126.80N0882231...  \n",
       "1  OBST TOWER LGT (ASR 1212822) 345040.40N0923322...  \n",
       "2  OBST TOWER LGT (ASR 1052889) 351222.50N0854828...  \n",
       "3  OBST TOWER LGT (ASR 1248915) 334516.20N0875825...  \n",
       "4  OBST TOWER LGT (ASR 1280021) 340633.40N0870610...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notam_location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KDVL</th>\n",
       "      <td>2019-01-10 01:00:00.0</td>\n",
       "      <td>2019-05-31 06:00:00.0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KDVT</th>\n",
       "      <td>2018-10-06 09:27:00.0</td>\n",
       "      <td>2019-06-28 22:44:00.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KFMY</th>\n",
       "      <td>2018-09-19 13:31:00.0</td>\n",
       "      <td>2019-05-31 18:00:00.0</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KHUA</th>\n",
       "      <td>2019-03-15 13:00:00.0</td>\n",
       "      <td>2019-06-07 17:00:00.0</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KLAX</th>\n",
       "      <td>2019-02-27 17:20:00.0</td>\n",
       "      <td>2019-06-14 19:30:00.0</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KLCQ</th>\n",
       "      <td>2019-01-02 19:45:00.0</td>\n",
       "      <td>2019-06-03 06:29:00.0</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMCO</th>\n",
       "      <td>2018-12-28 10:20:00.0</td>\n",
       "      <td>2019-06-30 18:00:00.0</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMOB</th>\n",
       "      <td>2019-03-26 11:20:00.0</td>\n",
       "      <td>2019-06-30 19:00:00.0</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMSY</th>\n",
       "      <td>2017-04-26 11:40:00.0</td>\n",
       "      <td>2019-06-30 18:00:00.0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KPHL</th>\n",
       "      <td>2018-12-14 05:00:00.0</td>\n",
       "      <td>2019-06-30 06:00:00.0</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KTUS</th>\n",
       "      <td>2018-11-19 10:00:00.0</td>\n",
       "      <td>2019-05-30 20:30:00.0</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TJSJ</th>\n",
       "      <td>2018-12-28 10:32:00.0</td>\n",
       "      <td>2019-06-30 17:00:00.0</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           start_time               end_time  keyword\n",
       "notam_location                                                       \n",
       "KDVL            2019-01-10 01:00:00.0  2019-05-31 06:00:00.0      142\n",
       "KDVT            2018-10-06 09:27:00.0  2019-06-28 22:44:00.0      270\n",
       "KFMY            2018-09-19 13:31:00.0  2019-05-31 18:00:00.0      256\n",
       "KHUA            2019-03-15 13:00:00.0  2019-06-07 17:00:00.0      146\n",
       "KLAX            2019-02-27 17:20:00.0  2019-06-14 19:30:00.0      108\n",
       "KLCQ            2019-01-02 19:45:00.0  2019-06-03 06:29:00.0      152\n",
       "KMCO            2018-12-28 10:20:00.0  2019-06-30 18:00:00.0      337\n",
       "KMOB            2019-03-26 11:20:00.0  2019-06-30 19:00:00.0      128\n",
       "KMSY            2017-04-26 11:40:00.0  2019-06-30 18:00:00.0      207\n",
       "KPHL            2018-12-14 05:00:00.0  2019-06-30 06:00:00.0      202\n",
       "KTUS            2018-11-19 10:00:00.0  2019-05-30 20:30:00.0      194\n",
       "TJSJ            2018-12-28 10:32:00.0  2019-06-30 17:00:00.0      341"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose locations with more than 100 NOTAMs\n",
    "selection = notam.groupby('notam_location').agg({'start_time': 'min', 'end_time': 'max', 'keyword': 'count'})\n",
    "filtered_selection = selection[(selection.keyword > 100)]\n",
    "filtered_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KDVL'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract these locations for use in METAR downloading\n",
    "focal_loc = filtered_selection.index.values\n",
    "focal_loc[0] # Showing this is now a list \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count                        12\n",
       "unique                       12\n",
       "top       2018-09-19 13:31:00.0\n",
       "freq                          1\n",
       "Name: start_time, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starts = filtered_selection.start_time\n",
    "ends = filtered_selection.end_time\n",
    "\n",
    "print(type(starts))\n",
    "starts.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get METARs for these locations and times\n",
    "\n",
    "- https://mesonet.agron.iastate.edu/request/download.phtml\n",
    "- https://github.com/akrherz/iem/blob/master/scripts/asos/iem_scraper_example.py\n",
    "\n",
    "Working steps:\n",
    "- Adapted functions from `iem_scraper_example.py`, currently in `metar_scraper.py`. Edit in that file, and use `%run metar_scraper` to import the functions into this notebook.\n",
    "- Changed main function to `get_metar` to use the specific start_time and end_time from filtered_selection data frame\n",
    "- Compiled in one DataFrame rather than downloading separately by station\n",
    "- Work on integrating METAR and NOTAM data and visualizing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provide DataFrame of stations and time range\n"
     ]
    }
   ],
   "source": [
    "# Edit function get_metar in \n",
    "# %load metar_scraper \n",
    "%run metar_scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch to Test download\n",
    "#SERVICE = \"http://mesonet.agron.iastate.edu/cgi-bin/request/asos.py?\"\n",
    "#service = SERVICE + \"data=all&tz=Etc/UTC&format=comma&latlon=yes&\"\n",
    "#startts = dt.datetime.strptime(filtered_selection['start_time'][0], '%Y-%m-%d %H:%M:%S.%f')\n",
    "#endts = dt.datetime.strptime(filtered_selection['end_time'][0], '%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "#station_service = service + startts.strftime('year1=%Y&month1=%m&day1=%d&')\n",
    "#station_service += endts.strftime('year2=%Y&month2=%m&day2=%d&')\n",
    "#uri = '%s&station=%s' % (station_service, filtered_selection.index[0])\n",
    "#print('Downloading: %s' % (filtered_selection.index[0], ))\n",
    "#data = download_data(uri)\n",
    "\n",
    "#df = pd.DataFrame([x.split(',') for x in data.split('\\n')])\n",
    "#df.columns = df.iloc[5] # Rename the columns with the values in the fifth row\n",
    "#df = df[6:].reset_index() # Keep only values from the sixth row on, and reset the row index\n",
    "#print(df)\n",
    "\n",
    "# View current working directory\n",
    "#import os\n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: KDVL\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-dd8400b8ddcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# get_metar(stations = focal_loc)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmetar_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_metar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltered_selection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\git\\notam-metar\\metar_scraper.py\u001b[0m in \u001b[0;36mget_metar\u001b[1;34m(stations)\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0muri\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%s&station=%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstation_service\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downloading: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdownload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;31m# Format data string as DataFrame, and keep just the data elements. Save as one large DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\git\\notam-metar\\metar_scraper.py\u001b[0m in \u001b[0;36mdownload_data\u001b[1;34m(uri)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mattempt\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mMAX_ATTEMPTS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ERROR'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readall_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_readall_chunked\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m                 \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_left\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;34mb''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    608\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m             \u001b[0mchunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get_metar(stations = focal_loc)\n",
    "metar_data = get_metar(stations = filtered_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     125503\n",
       "unique         3\n",
       "top          DVT\n",
       "freq       82155\n",
       "Name: station, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metar_data.describe()\n",
    "metar_data.station.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining METAR and NOTAM data\n",
    "\n",
    "- `metar_data` is now a DataFrame with all the necessary weather data for all stations.\n",
    "- We want to first trim this down to just the minimum necessary values (RVR and ceiling) \n",
    "- Then we want to join that with the counts of NOTAMs for each station.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notam_now = notam.loc[notam['notam_location'] == 'KDVL']\n",
    "notam_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datetime_object = datetime.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p')\n",
    "#datetime_object\n",
    "#base = datetime.today()\n",
    "#base\n",
    "#base\n",
    "\n",
    "max_end = max(notam_now['end_time'])\n",
    "min_start = min(notam_now['start_time'])\n",
    "print(base)\n",
    "start = dt.datetime.strptime(min_start, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "end = dt.datetime.strptime(max_end, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "print(datetime_object)\n",
    "difference = (end - start).total_seconds() / 60.0\n",
    "print(difference)\n",
    "date_list = [end - dt.timedelta(minutes=x) for x in range(0,int(difference),20)]\n",
    "print(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(date_list[::-1], columns=['Time'])\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"count\"] = 0\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2['count'] = len(notam_now[(notam_now['start_time']<=df2['count']) & (notam_now['end_time']>=df2['count'])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
